{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos el aÃ±o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv(f'datos\\counted\\d{year}_counted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Requires text preprocesssing (e.g., lowercasing, removing punctuation, stop words, stemming)\\\n",
    "The algortihm will be used just over 'avisocuerpo' because 'avisocargo' and 'avisorequisitos' are very similar and the algorithm identifies everything giving nothing interessting for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['avisocuerpo_t'] = data['avisocuerpo'].apply(lambda x: str(x).lower() if not pd.isna(x) else '')\n",
    "data['avisocuerpo_t'] = data['avisocuerpo_t'].apply(lambda x: x.replace('.', '').replace(',', '').replace(';', '').replace('-', '').replace('>', '').replace('<', '').replace('\\r', '').\n",
    "                                                replace('\\n', '').replace('\\n2', '').replace('\\n1', '').replace('\\n3', '').replace('\\\\', '').replace('/', '').replace('html', ''))\n",
    "data['avisocuerpo_t'] = data['avisocuerpo_t'].fillna('vacio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the size of the data is neccesary to do it by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Define the chunk size and calculate the number of chunks\n",
    "chunk_size = 1000  # You can adjust this as needed\n",
    "num_chunks = len(data) // chunk_size + 1\n",
    "\n",
    "# Initialize the 'duplicates' dictionary to store results\n",
    "duplicates = {}\n",
    "\n",
    "# Loop through the data in chunks\n",
    "for chunk_num in range(num_chunks):\n",
    "    start_idx = chunk_num * chunk_size\n",
    "    end_idx = start_idx + chunk_size\n",
    "    chunk_data = data.iloc[start_idx:end_idx].copy()  # Get a chunk of data\n",
    "    \n",
    "    # Fit and transform the job descriptions to TF-IDF vectors for the current chunk\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(chunk_data['avisocuerpo_t'].fillna('Vacio'))\n",
    "\n",
    "    # Calculate cosine similarity between job descriptions in the current chunk\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    # Define a similarity threshold, 0.5 to try to capture more similarities between the ads\n",
    "    similarity_threshold = 0.50\n",
    "\n",
    "    # Identify duplicates or similar job ads within the current chunk\n",
    "    for i in range(len(chunk_data)):\n",
    "        duplicates[start_idx + i] = [j for j, score in enumerate(cosine_sim[i]) if score > similarity_threshold and i != j]\n",
    "\n",
    "# Now, the 'duplicates' dictionary contains the results for the entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['similars'] = duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f'datos\\counted\\d{year}_counted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
