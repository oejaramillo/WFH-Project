{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the time partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pd.read_csv(f'datos\\counted\\d{tp}_counted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = data.loc[data['wfh'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = newData[newData.duplicated(subset=['empresaid', 'avisolugartrabajo'], keep='first')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61072"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(newData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pseudoindex for TF-IDF mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData['pseudoindex'] = range(len(newData))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "Requires text preprocesssing (e.g., lowercasing, removing punctuation, stop words, stemming)\\\n",
    "The algortihm will be used just over 'avisocuerpo' because 'avisocargo' and 'avisorequisitos' are very similar and the algorithm identifies everything giving nothing interessting for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData['avisocuerpo_t'] = newData['avisocuerpo'].apply(lambda x: str(x).lower() if not pd.isna(x) else '')\n",
    "newData['avisocuerpo_t'] = newData['avisocuerpo_t'].apply(lambda x: x.replace('.', ' ').replace(',', ' ').replace(';', ' ').replace('-', ' ').replace('>', ' ').replace('<', ' ').replace('\\r', ' ').\n",
    "                                                replace('\\n', ' ').replace('\\n2', ' ').replace('\\n1', ' ').replace('\\n3', ' ').replace('\\\\', ' ').replace('/', ' ').replace('html', ' '))\n",
    "newData['avisocuerpo_t'] = newData['avisocuerpo_t'].fillna('vacio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the size of the data is neccesary to do it by chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Define the chunk size and calculate the number of chunks\n",
    "chunk_size = 1000  # You can adjust this as needed\n",
    "num_chunks = len(newData) // chunk_size + 1\n",
    "\n",
    "# Initialize the 'duplicates' dictionary to store results\n",
    "duplicates = {}\n",
    "\n",
    "# Loop through the data in chunks\n",
    "for chunk_num in range(num_chunks):\n",
    "    start_idx = chunk_num * chunk_size\n",
    "    end_idx = start_idx + chunk_size\n",
    "    chunk_data = newData.iloc[start_idx:end_idx].copy()  # Get a chunk of data\n",
    "    \n",
    "    # Fit and transform the job descriptions to TF-IDF vectors for the current chunk\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(chunk_data['avisocuerpo_t'].fillna('Vacio'))\n",
    "\n",
    "    # Calculate cosine similarity between job descriptions in the current chunk\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "    # Define a similarity threshold, 0.5 to try to capture more similarities between the ads\n",
    "    similarity_threshold = 0.89\n",
    "\n",
    "    # Identify duplicates or similar job ads within the current chunk\n",
    "    for i in range(len(chunk_data)):\n",
    "        duplicates[start_idx + i] = [j for j, score in enumerate(cosine_sim[i]) if score > similarity_threshold and i != j]\n",
    "\n",
    "# Now, the 'duplicates' dictionary contains the results for the entire dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the job descriptions to TF-IDF vectors\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(newData['avisocuerpo'].fillna('Vacio'))\n",
    "\n",
    "# Calculate cosine similarity between job descriptions\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Define a similarity threshold (you can experiment with different values)\n",
    "similarity_threshold = 0.89\n",
    "\n",
    "# Identify duplicates or similar job ads\n",
    "duplicates = {}\n",
    "for i in range(len(newData)):\n",
    "    duplicates[i] = [j for j, score in enumerate(cosine_sim[i]) if score > similarity_threshold and i != j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData = newData.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData['similars'] = duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the WFH similars by 'avisoid' in the bigger data frame\n",
    "data['similars'] = data['avisoid'].map(newData.set_index('avisoid')['similars']).fillna('None')\n",
    "data['pseudoindex'] = data['avisoid'].map(newData.set_index('avisoid')['pseudoindex']).fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pseudoindex</th>\n",
       "      <th>similars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1.0</td>\n",
       "      <td>[2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2.0</td>\n",
       "      <td>[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>3.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>4.0</td>\n",
       "      <td>[233, 234]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730299</th>\n",
       "      <td>61067.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730306</th>\n",
       "      <td>61068.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730307</th>\n",
       "      <td>61069.0</td>\n",
       "      <td>[70]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730309</th>\n",
       "      <td>61070.0</td>\n",
       "      <td>[69]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730310</th>\n",
       "      <td>61071.0</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61072 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pseudoindex    similars\n",
       "75             0.0          []\n",
       "87             1.0         [2]\n",
       "88             2.0         [1]\n",
       "89             3.0          []\n",
       "115            4.0  [233, 234]\n",
       "...            ...         ...\n",
       "730299     61067.0          []\n",
       "730306     61068.0          []\n",
       "730307     61069.0        [70]\n",
       "730309     61070.0        [69]\n",
       "730310     61071.0          []\n",
       "\n",
       "[61072 rows x 2 columns]"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['pseudoindex'] != 'None'][['pseudoindex', 'similars']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f'datos\\\\counted\\d{tp}_counted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "newData.to_csv(f'datos\\\\similars\\d{tp}_similars.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
