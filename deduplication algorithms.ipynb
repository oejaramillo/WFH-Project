{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\OscarJaramillo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_rs.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to deduplicate the ads by a cosine similarity function, but we're going to encode first the strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mantaining the order of the words in the string to try to capture semantic differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 1, 4, 8, 9, 2, 2, 4, 3, 3]\n",
      "{'this': 1, 'is': 2, 'a': 3, 'test': 4, 'to': 5, 'see': 6, 'if': 7, 'will': 8, 'work': 9}\n"
     ]
    }
   ],
   "source": [
    "vocab = {}\n",
    "word_encoding = 1\n",
    "def one_hot_encoding(text):\n",
    "  global word_encoding\n",
    "\n",
    "  words = text.lower().split(\" \")\n",
    "  encoding = []\n",
    "\n",
    "  for word in words:\n",
    "    if word in vocab:\n",
    "      code = vocab[word]\n",
    "      encoding.append(code)\n",
    "    else:\n",
    "      vocab[word] = word_encoding\n",
    "      encoding.append(word_encoding)\n",
    "      word_encoding += 1\n",
    "\n",
    "  return encoding\n",
    "\n",
    "text = \"this is a test to see if this test will work is is test a a\"\n",
    "encoding = one_hot_encoding(text)\n",
    "print(encoding)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires text preprocesssing (e.g., lowercasing, removing punctuation, stop words, stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "np.nan is an invalid document, expected byte or unicode string.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Oscar Local\\WFH-Project\\deduplication algorithms.ipynb Cell 10\u001b[0m line \u001b[0;36m5\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Oscar%20Local/WFH-Project/deduplication%20algorithms.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tfidf_vectorizer \u001b[39m=\u001b[39m TfidfVectorizer()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Oscar%20Local/WFH-Project/deduplication%20algorithms.ipynb#X12sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Fit and transform the job descriptions to TF-IDF vectors\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Oscar%20Local/WFH-Project/deduplication%20algorithms.ipynb#X12sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m tfidf_matrix \u001b[39m=\u001b[39m tfidf_vectorizer\u001b[39m.\u001b[39;49mfit_transform(data[\u001b[39m'\u001b[39;49m\u001b[39mavisocuerpo\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Oscar%20Local/WFH-Project/deduplication%20algorithms.ipynb#X12sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Calculate cosine similarity between job descriptions\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Oscar%20Local/WFH-Project/deduplication%20algorithms.ipynb#X12sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m cosine_sim \u001b[39m=\u001b[39m cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
      "File \u001b[1;32mc:\\Users\\OscarJaramillo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:2126\u001b[0m, in \u001b[0;36mTfidfVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   2119\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_params()\n\u001b[0;32m   2120\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf \u001b[39m=\u001b[39m TfidfTransformer(\n\u001b[0;32m   2121\u001b[0m     norm\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm,\n\u001b[0;32m   2122\u001b[0m     use_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_idf,\n\u001b[0;32m   2123\u001b[0m     smooth_idf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msmooth_idf,\n\u001b[0;32m   2124\u001b[0m     sublinear_tf\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msublinear_tf,\n\u001b[0;32m   2125\u001b[0m )\n\u001b[1;32m-> 2126\u001b[0m X \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit_transform(raw_documents)\n\u001b[0;32m   2127\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tfidf\u001b[39m.\u001b[39mfit(X)\n\u001b[0;32m   2128\u001b[0m \u001b[39m# X is already a transformed view of raw_documents so\u001b[39;00m\n\u001b[0;32m   2129\u001b[0m \u001b[39m# we set copy to False\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\OscarJaramillo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\OscarJaramillo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1383\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1375\u001b[0m             warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1376\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mUpper case characters found in\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1377\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m vocabulary while \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlowercase\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1378\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m is True. These entries will not\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1379\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m be matched with any documents\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1380\u001b[0m             )\n\u001b[0;32m   1381\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m-> 1383\u001b[0m vocabulary, X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_count_vocab(raw_documents, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfixed_vocabulary_)\n\u001b[0;32m   1385\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbinary:\n\u001b[0;32m   1386\u001b[0m     X\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mfill(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\OscarJaramillo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:1270\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1268\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m raw_documents:\n\u001b[0;32m   1269\u001b[0m     feature_counter \u001b[39m=\u001b[39m {}\n\u001b[1;32m-> 1270\u001b[0m     \u001b[39mfor\u001b[39;00m feature \u001b[39min\u001b[39;00m analyze(doc):\n\u001b[0;32m   1271\u001b[0m         \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1272\u001b[0m             feature_idx \u001b[39m=\u001b[39m vocabulary[feature]\n",
      "File \u001b[1;32mc:\\Users\\OscarJaramillo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:105\u001b[0m, in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Chain together an optional series of text processing steps to go from\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39ma single document to ngrams, with or without tokenizing or preprocessing.\u001b[39;00m\n\u001b[0;32m     85\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39m    A sequence of tokens, possibly with pairs, triples, etc.\u001b[39;00m\n\u001b[0;32m    102\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[39mif\u001b[39;00m decoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 105\u001b[0m     doc \u001b[39m=\u001b[39m decoder(doc)\n\u001b[0;32m    106\u001b[0m \u001b[39mif\u001b[39;00m analyzer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    107\u001b[0m     doc \u001b[39m=\u001b[39m analyzer(doc)\n",
      "File \u001b[1;32mc:\\Users\\OscarJaramillo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\feature_extraction\\text.py:238\u001b[0m, in \u001b[0;36m_VectorizerMixin.decode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    235\u001b[0m     doc \u001b[39m=\u001b[39m doc\u001b[39m.\u001b[39mdecode(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecode_error)\n\u001b[0;32m    237\u001b[0m \u001b[39mif\u001b[39;00m doc \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mnan:\n\u001b[1;32m--> 238\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    239\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mnp.nan is an invalid document, expected byte or unicode string.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    240\u001b[0m     )\n\u001b[0;32m    242\u001b[0m \u001b[39mreturn\u001b[39;00m doc\n",
      "\u001b[1;31mValueError\u001b[0m: np.nan is an invalid document, expected byte or unicode string."
     ]
    }
   ],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the job descriptions to TF-IDF vectors\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['avisocuerpo'])\n",
    "\n",
    "# Calculate cosine similarity between job descriptions\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Define a similarity threshold (you can experiment with different values)\n",
    "similarity_threshold = 0.85\n",
    "\n",
    "# Identify duplicates or similar job ads\n",
    "duplicates = {}\n",
    "for i in range(len(data)):\n",
    "    duplicates[i] = [j for j, score in enumerate(cosine_sim[i]) if score > similarity_threshold and i != j]\n",
    "\n",
    "# Print the duplicates\n",
    "for key, value in duplicates.items():\n",
    "    if value:\n",
    "        print(f\"Job Ad {key} is similar to: {value}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Word2Vec model in gensim for spanish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requires text preprocesssing (e.g., lowercasing, removing punctuation, stop words, stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['avisocuerpo'] = data['avisocuerpo'].apply(lambda x: str(x).lower() if not pd.isna(x) else '')\n",
    "data['avisocuerpo'] = data['avisocuerpo'].apply(lambda x: x.replace('.', '').replace(',', '').replace(';', '').replace('-', '').replace('>', '').replace('<', '').replace('\\r', '').\n",
    "                                                replace('\\n', '').replace('\\n2', '').replace('\\n1', '').replace('\\n3', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize avisocuerpo\n",
    "data['tokens'] = data['avisocuerpo'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Train Word2Vec model on the tokenized job descriptions\n",
    "model = Word2Vec(data['tokens'], vector_size=100, window=2, min_count=1, sg=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can think in increasing vector size to capture more relationships between words but it'll require more computer power \\\n",
    "Another possibility is to increase window parameter that will give more context between read and predicted word, this should give more context to the model and it should capture better the word embeddings \\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to compare ads, after training the Word2Vec model, we need to compute vectors for entire job descriptions. we'll do this by averaging the vectors of all words in a job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ads_vector(tokens, model):\n",
    "\n",
    "    # Is important to ensure the model has seen these words during training\n",
    "    valid_tokens = [token for token in tokens if token in model.wv]\n",
    "    if valid_tokens:        \n",
    "        return np.mean(model.wv[valid_tokens], axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Calculate vectors for all job descriptions\n",
    "data['ads_vectors'] = data['tokens'].apply(lambda x: get_ads_vector(x, model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define cosine similarity because we can't use cosine_similarity from sklearn.metrics.pairwise because it compares a mean ad from the column with other ad but in our case we want to compare row by row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(vec1, vec2):\n",
    "    return 1 - distance.cosine(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OscarJaramillo\\AppData\\Local\\Temp\\ipykernel_9276\\1168873156.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['compare'][x] = calculate_cosine_similarity(data['ads_vectors'][111754], data['ads_vectors'][x])\n",
      "c:\\Users\\OscarJaramillo\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\spatial\\distance.py:622: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n"
     ]
    }
   ],
   "source": [
    "data['compare'] = None\n",
    "for x in data.index:\n",
    "    data['compare'][x] = calculate_cosine_similarity(data['ads_vectors'][111754], data['ads_vectors'][x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pyindex</th>\n",
       "      <th>avisoid</th>\n",
       "      <th>empresaid</th>\n",
       "      <th>avisofechapublicacion</th>\n",
       "      <th>avisovacante</th>\n",
       "      <th>mostrarsueldo</th>\n",
       "      <th>avisoexperiencia</th>\n",
       "      <th>expiracion</th>\n",
       "      <th>dias</th>\n",
       "      <th>avisorepublicacion</th>\n",
       "      <th>...</th>\n",
       "      <th>avre_b4</th>\n",
       "      <th>bucket1</th>\n",
       "      <th>bucket2</th>\n",
       "      <th>bucket3</th>\n",
       "      <th>bucket4</th>\n",
       "      <th>wfh</th>\n",
       "      <th>duplicated</th>\n",
       "      <th>tokens</th>\n",
       "      <th>ads_vectors</th>\n",
       "      <th>compare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111754</th>\n",
       "      <td>112413</td>\n",
       "      <td>346860.0</td>\n",
       "      <td>7313</td>\n",
       "      <td>2008-10-23</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2008-11-22 00:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[buscamos, a, los, (, as, ), mejores, ingenier...</td>\n",
       "      <td>[-0.140401, 0.20520142, 0.06415321, 0.03093196...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93342</th>\n",
       "      <td>93822</td>\n",
       "      <td>326390.0</td>\n",
       "      <td>584268</td>\n",
       "      <td>2008-09-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-10-13 00:00:00</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[nuestra, empresa, está, en, la, búsqueda, de,...</td>\n",
       "      <td>[-0.12033648, 0.17702962, 0.0541395, 0.0258496...</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49021</th>\n",
       "      <td>49320</td>\n",
       "      <td>270171.0</td>\n",
       "      <td>576806</td>\n",
       "      <td>2008-05-13</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2008-06-27 00:00:00</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126275</th>\n",
       "      <td>127283</td>\n",
       "      <td>363468.0</td>\n",
       "      <td>36916</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-12-15 00:00:00</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>[]</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5729</th>\n",
       "      <td>5945</td>\n",
       "      <td>209044.0</td>\n",
       "      <td>11758</td>\n",
       "      <td>2008-01-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008-04-16 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[importante, empresa, requiere, contratar, jef...</td>\n",
       "      <td>[-0.12791647, 0.18601729, 0.057467714, 0.02645...</td>\n",
       "      <td>0.999991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126268</th>\n",
       "      <td>127276</td>\n",
       "      <td>363461.0</td>\n",
       "      <td>5895</td>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-12-16 00:00:00</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[la, gerencia, de, inteligencia, de, negocios,...</td>\n",
       "      <td>[-0.14058644, 0.20574825, 0.06316621, 0.028923...</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44800</th>\n",
       "      <td>45091</td>\n",
       "      <td>252376.0</td>\n",
       "      <td>37787</td>\n",
       "      <td>2008-05-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008-08-20 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[requerimos, contratar, jefe, de, provedores, ...</td>\n",
       "      <td>[-0.12272077, 0.17980039, 0.054967012, 0.02582...</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74749</th>\n",
       "      <td>75145</td>\n",
       "      <td>306656.0</td>\n",
       "      <td>6618</td>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008-09-11 00:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[avisoimportante, empresa, de, servicios, oper...</td>\n",
       "      <td>[-0.1374337, 0.20129167, 0.061905827, 0.029267...</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84495</th>\n",
       "      <td>84959</td>\n",
       "      <td>317405.0</td>\n",
       "      <td>7161</td>\n",
       "      <td>2008-09-10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-12-09 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>[buscamos, profesional, responsable, del, cont...</td>\n",
       "      <td>[-0.133996, 0.19647096, 0.06099388, 0.02898169...</td>\n",
       "      <td>0.999993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49819</th>\n",
       "      <td>50120</td>\n",
       "      <td>273698.0</td>\n",
       "      <td>25662</td>\n",
       "      <td>2008-05-30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008-08-28 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[a, cargo, de, :, •, aplicar, en, sistema, los...</td>\n",
       "      <td>[-0.12959811, 0.18908538, 0.058618434, 0.02798...</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90078</th>\n",
       "      <td>90558</td>\n",
       "      <td>323126.0</td>\n",
       "      <td>582884</td>\n",
       "      <td>2008-05-09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008-10-13 00:00:00</td>\n",
       "      <td>157</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[perfil, :, *, egresada, de, la, carrera, de, ...</td>\n",
       "      <td>[-0.13142727, 0.19201015, 0.05892286, 0.027574...</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72660</th>\n",
       "      <td>73045</td>\n",
       "      <td>304366.0</td>\n",
       "      <td>6260</td>\n",
       "      <td>2008-08-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2008-09-04 00:00:00</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[empresa, del, rubro, industrial, pertenecient...</td>\n",
       "      <td>[-0.123700365, 0.18069589, 0.054951042, 0.0257...</td>\n",
       "      <td>0.999991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61390</th>\n",
       "      <td>61736</td>\n",
       "      <td>291948.0</td>\n",
       "      <td>45500</td>\n",
       "      <td>2008-07-03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2008-10-01 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[a, cargo, de, :, •, aplicar, en, sistema, los...</td>\n",
       "      <td>[-0.12959811, 0.18908538, 0.058618434, 0.02798...</td>\n",
       "      <td>0.99999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>2283</td>\n",
       "      <td>205076.0</td>\n",
       "      <td>38369</td>\n",
       "      <td>2008-01-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2008-04-06 00:00:00</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>[empresa, distribuidora, de, materiales, de, c...</td>\n",
       "      <td>[-0.13271701, 0.19473274, 0.0603746, 0.0274650...</td>\n",
       "      <td>0.999991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pyindex   avisoid  empresaid avisofechapublicacion  avisovacante  \\\n",
       "111754   112413  346860.0       7313            2008-10-23           3.0   \n",
       "93342     93822  326390.0     584268            2008-09-03           1.0   \n",
       "49021     49320  270171.0     576806            2008-05-13           2.0   \n",
       "126275   127283  363468.0      36916            2008-12-01           1.0   \n",
       "5729       5945  209044.0      11758            2008-01-17           1.0   \n",
       "126268   127276  363461.0       5895            2008-12-01           3.0   \n",
       "44800     45091  252376.0      37787            2008-05-22           1.0   \n",
       "74749     75145  306656.0       6618            2008-08-12           1.0   \n",
       "84495     84959  317405.0       7161            2008-09-10           1.0   \n",
       "49819     50120  273698.0      25662            2008-05-30           1.0   \n",
       "90078     90558  323126.0     582884            2008-05-09           1.0   \n",
       "72660     73045  304366.0       6260            2008-08-05           1.0   \n",
       "61390     61736  291948.0      45500            2008-07-03           1.0   \n",
       "2074       2283  205076.0      38369            2008-01-07           1.0   \n",
       "\n",
       "        mostrarsueldo  avisoexperiencia           expiracion  dias  \\\n",
       "111754            0.0               4.0  2008-11-22 00:00:00    30   \n",
       "93342             NaN               NaN  2008-10-13 00:00:00    40   \n",
       "49021             NaN               0.0  2008-06-27 00:00:00    45   \n",
       "126275            NaN               NaN  2008-12-15 00:00:00    14   \n",
       "5729              0.0               2.0  2008-04-16 00:00:00    90   \n",
       "126268            0.0               NaN  2008-12-16 00:00:00    15   \n",
       "44800             1.0               5.0  2008-08-20 00:00:00    90   \n",
       "74749             0.0               5.0  2008-09-11 00:00:00    30   \n",
       "84495             0.0               NaN  2008-12-09 00:00:00    90   \n",
       "49819             0.0               2.0  2008-08-28 00:00:00    90   \n",
       "90078             NaN               NaN  2008-10-13 00:00:00   157   \n",
       "72660             0.0               7.0  2008-09-04 00:00:00    30   \n",
       "61390             0.0               5.0  2008-10-01 00:00:00    90   \n",
       "2074              0.0               2.0  2008-04-06 00:00:00    90   \n",
       "\n",
       "        avisorepublicacion  ... avre_b4 bucket1 bucket2 bucket3 bucket4 wfh  \\\n",
       "111754                   0  ...   False       0       0       0       0   0   \n",
       "93342                    0  ...   False       0       0       0       0   0   \n",
       "49021                    0  ...   False       0       0       0       0   0   \n",
       "126275                   0  ...   False       0       0       0       0   0   \n",
       "5729                     0  ...   False       0       0       0       0   0   \n",
       "126268                   0  ...   False       0       0       0       0   0   \n",
       "44800                    0  ...   False       0       0       0       0   0   \n",
       "74749                    0  ...   False       0       0       0       0   0   \n",
       "84495                    0  ...   False       0       0       0       0   0   \n",
       "49819                    0  ...   False       0       1       0       0   1   \n",
       "90078                    0  ...   False       1       0       0       0   1   \n",
       "72660                    0  ...   False       0       0       1       0   1   \n",
       "61390                    0  ...   False       0       1       0       0   1   \n",
       "2074                     0  ...   False       1       0       0       0   1   \n",
       "\n",
       "       duplicated                                             tokens  \\\n",
       "111754      False  [buscamos, a, los, (, as, ), mejores, ingenier...   \n",
       "93342       False  [nuestra, empresa, está, en, la, búsqueda, de,...   \n",
       "49021       False                                                 []   \n",
       "126275       True                                                 []   \n",
       "5729        False  [importante, empresa, requiere, contratar, jef...   \n",
       "126268      False  [la, gerencia, de, inteligencia, de, negocios,...   \n",
       "44800       False  [requerimos, contratar, jefe, de, provedores, ...   \n",
       "74749       False  [avisoimportante, empresa, de, servicios, oper...   \n",
       "84495       False  [buscamos, profesional, responsable, del, cont...   \n",
       "49819       False  [a, cargo, de, :, •, aplicar, en, sistema, los...   \n",
       "90078       False  [perfil, :, *, egresada, de, la, carrera, de, ...   \n",
       "72660       False  [empresa, del, rubro, industrial, pertenecient...   \n",
       "61390       False  [a, cargo, de, :, •, aplicar, en, sistema, los...   \n",
       "2074        False  [empresa, distribuidora, de, materiales, de, c...   \n",
       "\n",
       "                                              ads_vectors   compare  \n",
       "111754  [-0.140401, 0.20520142, 0.06415321, 0.03093196...         1  \n",
       "93342   [-0.12033648, 0.17702962, 0.0541395, 0.0258496...   0.99999  \n",
       "49021   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         1  \n",
       "126275  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         1  \n",
       "5729    [-0.12791647, 0.18601729, 0.057467714, 0.02645...  0.999991  \n",
       "126268  [-0.14058644, 0.20574825, 0.06316621, 0.028923...   0.99999  \n",
       "44800   [-0.12272077, 0.17980039, 0.054967012, 0.02582...  0.999992  \n",
       "74749   [-0.1374337, 0.20129167, 0.061905827, 0.029267...  0.999992  \n",
       "84495   [-0.133996, 0.19647096, 0.06099388, 0.02898169...  0.999993  \n",
       "49819   [-0.12959811, 0.18908538, 0.058618434, 0.02798...   0.99999  \n",
       "90078   [-0.13142727, 0.19201015, 0.05892286, 0.027574...  0.999994  \n",
       "72660   [-0.123700365, 0.18069589, 0.054951042, 0.0257...  0.999991  \n",
       "61390   [-0.12959811, 0.18908538, 0.058618434, 0.02798...   0.99999  \n",
       "2074    [-0.13271701, 0.19473274, 0.0603746, 0.0274650...  0.999991  \n",
       "\n",
       "[14 rows x 48 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['compare'] >= threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data['compare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7456258535385132"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data['compare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'empresa distribuidora de materiales de construccion busca encargado de producto  la persona deberá administrar líneas de productos incluyendo atributos de precio físicos etc de manera de contar con el mix adecuado que cumpla las expectativas de los clientes y maximice la rentabilidad de la compañía    dentro de sus principales funciones se pueden mencionar:  identificar definir y crear productos en sistema  identificar categorías y subcategorías de productos  proponer cambios en el mix de productos de acuerdo a la demanda de mercado  definir y analizar la rentabilidad y rotación de cada categoría  mantener precios de compra y venta de productos  establecer relación con fábricas proveedoras a través del depto de adquisiciones'"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['avisocuerpo'][2074]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'buscamos profesional responsable del control de gestión de importante grupo de empresas de comunicaciones corporativas que entre otras cosas sea capaz de:\\r\\n\\r\\n1) liderar organizar y administrar proyectos de control de gestión y mejoramiento de procesos transversales entre las unidades de negocio y empresas relacionadas\\r\\n\\r\\n2) generar mecanismos de control de gestión a través de reportes coordinación y monitoreo de fuentes externas de información con el objetivo de mantener informados a los distintos estamentos del grupo sobre el cumplimiento de metas y estado de proyectos\\r\\n\\r\\n3) apoyar la organización del trabajo de personal del área administrativa y contable generando reportes financieros y de procesos para la gerencia\\r\\n \\r\\nse ofrece gran estabilidad laboral y un grato ambiente de trabajo\\r\\n\\r\\nsólo se revisarán currículums que incluyan pretensiones de renta líquida'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['avisocuerpo'][84495]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
